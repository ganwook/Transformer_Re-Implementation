{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch master [doc](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get some batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import get_data\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/\"\n",
    "file_name = \"train.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_en, train_en = get_data(file_path = data_path + file_name + 'en',\n",
    "                           field_name = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.Iterator(train_en, batch_size = 3,\n",
    "                            device = None, # if using GPU, type \"cuda\" \n",
    "                            repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = batch.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del txt_en, train_en, train_loader, batch.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 26])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "- super().__init__() : nn.Module의 __init__() 상속\n",
    "[ref](https://rednooby.tistory.com/56)\n",
    "- nn.Embedding(V, D) : V = #(Vocab), D = #(Dim)\n",
    "V, D 만큼의 Embedding 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model, padding_idx = 1)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(25000,128, padding_idx = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = Embeddings(d_model = 128, vocab = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = emb(b).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -2.6353, -15.7527,  -7.7449,  ..., -16.0526,   3.2284,   0.6601],\n",
       "         [ -0.2340,  -6.2271, -14.6666,  ...,   6.2826,  -1.4128,   9.5129],\n",
       "         [ 11.2771,   0.1608,  -9.7236,  ..., -11.5052,  -4.3630,  -2.4111],\n",
       "         ...,\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000],\n",
       "         [  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]],\n",
       "       grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 128])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Encoding\n",
    "\n",
    "\"::\" : seq[start:end:step] \n",
    "\n",
    "torch.nn.register_buffer : Adds a persistent buffer to the module.\n",
    "torch.autograd.Variable : 이후 Gradient 흘려줄 변수로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        pe = torch.zeros(max_len, d_model, dtype = torch.float)\n",
    "        position = torch.arange(0, max_len, dtype = torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype = torch.float) / \n",
    "                             d_model * -math.log(1e+4))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad = False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 128\n",
    "max_len = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "PE = PositionalEncoding(d_model = 128, dropout = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 128])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2729,  2.7363, -0.4536,  ...,  1.0792, -0.8988,  0.6352],\n",
       "         [-0.2253,  0.4553,  1.4877,  ...,  2.5368, -0.1377,  0.1559],\n",
       "         [-0.4945,  1.2978, -0.6154,  ...,  0.8582, -0.0852,  2.1106],\n",
       "         ...,\n",
       "         [-0.9402, -0.5920,  0.9734,  ...,  1.1111,  0.0030,  1.1111],\n",
       "         [-1.0062,  0.4713,  1.0388,  ...,  1.1111,  0.0031,  1.1111],\n",
       "         [-0.0000,  1.1013,  0.3727,  ...,  1.1111,  0.0032,  1.1111]]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE.forward(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 판깔기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = torch.zeros(max_len, d_model, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 각 텀 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(0, max_len, dtype = torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [2.0000e+00],\n",
       "        ...,\n",
       "        [4.9970e+03],\n",
       "        [4.9980e+03],\n",
       "        [4.9990e+03]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "div_term = torch.exp(torch.arange(0, d_model, 2, dtype = torch.float) / d_model * -math.log(1e+4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        -2.9802e-08, -2.9802e-08,  2.9802e-08,  0.0000e+00, -2.9802e-08,\n",
       "        -2.9802e-08,  0.0000e+00,  0.0000e+00, -1.4901e-08,  0.0000e+00,\n",
       "         0.0000e+00, -7.4506e-09,  0.0000e+00, -7.4506e-09, -7.4506e-09,\n",
       "        -7.4506e-09,  3.7253e-09,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "        -1.8626e-09, -3.7253e-09, -3.7253e-09,  0.0000e+00, -2.7940e-09,\n",
       "         0.0000e+00, -2.7940e-09,  0.0000e+00,  9.3132e-10, -1.3970e-09,\n",
       "         4.6566e-10, -9.3132e-10,  0.0000e+00, -9.3132e-10, -2.3283e-10,\n",
       "        -9.3132e-10, -4.6566e-10,  0.0000e+00, -4.6566e-10,  0.0000e+00,\n",
       "        -3.4925e-10, -1.1642e-10, -3.4925e-10, -1.1642e-10,  1.1642e-10,\n",
       "        -1.1642e-10,  5.8208e-11, -1.1642e-10, -2.9104e-11, -1.4552e-10,\n",
       "         0.0000e+00,  5.8208e-11,  8.7311e-11, -1.0186e-10, -4.3656e-11,\n",
       "         0.0000e+00,  2.9104e-11, -7.2760e-11, -4.3656e-11])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pow 연산 위치에 따른 비교\n",
    "div_term - torch.pow(10000, -torch.arange(0, d_model, 2, dtype = torch.float) / d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([5000, 1]) torch.Size([5000, 128])\n"
     ]
    }
   ],
   "source": [
    "print(div_term.shape, position.shape, pe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 64])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(position * div_term).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pe.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0],\n",
       "        [   1],\n",
       "        [   2],\n",
       "        ...,\n",
       "        [4997],\n",
       "        [4998],\n",
       "        [4999]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5000).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5000, 128])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def forward 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5000, 128])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, ].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 128])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe[:, :x.size(1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 26, 128])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(pe[:, :x.size(1)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,   135,    55,    11,  3553,    35,  9896,  1040,     6,   900,\n",
       "           26, 21687,    19,  1405,    10,     4,   109,   668,     3,     1,\n",
       "            1,     1,     1,     1,     1,     1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
