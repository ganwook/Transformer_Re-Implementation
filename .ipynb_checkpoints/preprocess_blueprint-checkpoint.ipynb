{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset/\"\n",
    "file_name = \"train.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "BLANK_WORD = \"<blank>\"\n",
    "MAX_LEN = 100\n",
    "MIN_FREQ = 2\n",
    "DEVICE_SET = None\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_en = data.Field(sequential = True, use_vocab = True,\n",
    "                    batch_first = True,tokenize=str.split, \n",
    "                    init_token = BOS_WORD,                   \n",
    "                 eos_token = EOS_WORD, pad_token=BLANK_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_de = data.Field(sequential = True, use_vocab = True,\n",
    "                    batch_first = True,tokenize=str.split, \n",
    "                    init_token = BOS_WORD,                   \n",
    "                    eos_token = EOS_WORD, pad_token=BLANK_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = data.TabularDataset(path= data_path + file_name + 'en', \n",
    "                             fields = [('en', txt_en)],\n",
    "                             format = 'tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_de = data.TabularDataset(path= data_path + file_name + 'de', \n",
    "                             fields = [('de', txt_de)],\n",
    "                             format = 'tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_en.build_vocab(train_en, min_freq = MIN_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(txt_en.vocab.stoi['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>\n"
     ]
    }
   ],
   "source": [
    "print(txt_en.vocab.itos[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.Iterator(train_en, batch_size = BATCH_SIZE,\n",
    "                            device = DEVICE_SET, # if using GPU, type \"cuda\" \n",
    "                            repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,  1303,  2645, 30315,   760,   165,    11,    36,    87,    21,\n",
      "             8,   327,    19,   165,     3,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,    14,  3280, 25559,   255,     7,    76, 25559,    35,   512,\n",
      "            56,    25,    57,   150,     5,   478,    81,  4904,     3,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [    2,    14,    39,    15,    21,    24,     4,  1693,   476,    28,\n",
      "            42,     6,    35,  1829,  3262,     5,   238,     4,     0,     0,\n",
      "         10621,   420,    74,    20,     4,  4018,    74,    20, 33981,  5390,\n",
      "         22136,    74,   195,   173,     8,  1680,     3]])\n"
     ]
    }
   ],
   "source": [
    "print(batch.en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==================================\n",
    "# Import test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_en, train_en = get_data(file_path = data_path + file_name + 'en',\n",
    "                           field_name = 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
