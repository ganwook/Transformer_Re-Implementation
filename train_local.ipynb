{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yYJZITCQnSK0"
   },
   "outputs": [],
   "source": [
    "import model as trf\n",
    "from process import get_data\n",
    "from train import *\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lb9xq1bBoEvG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_SET = None\n",
    "BATCH_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tip9UAXHoHpO"
   },
   "outputs": [],
   "source": [
    "data_path = \"dataset/\"\n",
    "file_name = \"train.\"\n",
    "save_path = \"model_save/transformer_epoch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GL2CA2_LoJ6C"
   },
   "outputs": [],
   "source": [
    "SRC, TGT, trn = get_data(data_path + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na5mUV2aoY8h"
   },
   "outputs": [],
   "source": [
    "pad_idx = TGT.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zxvu8wm0oagt"
   },
   "outputs": [],
   "source": [
    "model = trf.Transformer(len(SRC.vocab), len(TGT.vocab), N = 6)\n",
    "#model.cuda() # .to(\"cuda:0\") : \n",
    "criterion = nn.NLLLoss(ignore_index = 1)\n",
    "#criterion.cuda()\n",
    "model_opt = torch.optim.Adam(model.parameters(), lr = .1, betas=(.9, .98), eps = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I84_V_cboqAK"
   },
   "outputs": [],
   "source": [
    "train_iter = data.Iterator(trn, batch_size = BATCH_SIZE,\n",
    "                          device = None,\n",
    "                          repeat = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs, model, criterion, model_opt, train_iter, save_path, print_every = 100):\n",
    "    \n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    mean_tokens = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            \n",
    "            src = batch.en\n",
    "            tgt = batch.de\n",
    "            \n",
    "            # equalize sequence length of batches, originated from torchtext\n",
    "            diff_ = src.size(-1) - tgt.size(-1)\n",
    "            bal_pad = torch.ones(BATCH_SIZE, abs(diff_), dtype = torch.long)\n",
    "\n",
    "            if diff_ < 0:\n",
    "                src = torch.cat((src, bal_pad), dim = 1)\n",
    "            elif diff_ > 0:\n",
    "                tgt = torch.cat((tgt, bal_pad), dim = 1)\n",
    "                \n",
    "            bat = Batch(src, tgt) # from train.Batch\n",
    "            \n",
    "            hidden = model.forward(bat.src, bat.trg, bat.src_mask, bat.trg_mask)\n",
    "            preds = model.generator(hidden)\n",
    "\n",
    "            model_opt.zero_grad()\n",
    "\n",
    "            loss = criterion(preds.contiguous().view(-1, preds.size(-1)),\n",
    "                            bat.trg_y.contiguous().view(-1))\n",
    "            loss.backward()\n",
    "\n",
    "            model_opt.step()\n",
    "\n",
    "            total_loss += loss.data\n",
    "            mean_tokens += bat.ntokens / BATCH_SIZE\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                elapsed = time.time() - start\n",
    "                print(\"Iteration Step: %d Loss per token: %f per Sec: %f #(tokens) : %d\" %\n",
    "                        (i, total_loss / mean_tokens , elapsed, mean_tokens / print_every))\n",
    "                start = time.time()\n",
    "                \n",
    "                total_loss = 0\n",
    "                mean_tokens = 0\n",
    "\n",
    "        torch.save(model.state_dict(), save_path + str(i) + \".pt\") # save check point\n",
    "        print(\"Epoch Step : %d is done\" %(epcoh))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31496706,
     "status": "error",
     "timestamp": 1565225850984,
     "user": {
      "displayName": "김강우",
      "photoUrl": "",
      "userId": "13809575073066285378"
     },
     "user_tz": -540
    },
    "id": "nHBEZrkqq8A4",
    "outputId": "08afcf82-965f-4a94-b130-9d6725b9d40c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration Step: 0 Loss per token: 0.627188 per Sec: 4.965740 #(tokens) : 3\n",
      "Iteration Step: 5 Loss per token: 5.101102 per Sec: 33.744342 #(tokens) : 14\n",
      "Iteration Step: 10 Loss per token: 3.167434 per Sec: 31.484677 #(tokens) : 18\n",
      "Iteration Step: 15 Loss per token: 2.032048 per Sec: 26.491583 #(tokens) : 14\n",
      "Iteration Step: 20 Loss per token: 0.863235 per Sec: 30.420695 #(tokens) : 17\n",
      "Iteration Step: 25 Loss per token: 0.729698 per Sec: 32.973776 #(tokens) : 19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a62b0ff524f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-6082294c973f>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(epochs, model, criterion, model_opt, train_iter, save_path, print_every)\u001b[0m\n\u001b[0;32m     30\u001b[0m             loss = criterion(preds.contiguous().view(-1, preds.size(-1)),\n\u001b[0;32m     31\u001b[0m                             bat.trg_y.contiguous().view(-1))\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mmodel_opt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\colab\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\colab\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(1, model, criterion, model_opt, train_iter, save_path, print_every = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
